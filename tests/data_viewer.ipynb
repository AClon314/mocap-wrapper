{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use with `vscode` and its `Data Wrangler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "_GLOBAL = {}\n",
    "def load_pt(file):\n",
    "    data = torch.load(file)\n",
    "    return data\n",
    "\n",
    "def load_pkl(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def load_np(file):\n",
    "    return np.load(file, allow_pickle=True)\n",
    "    \n",
    "def load(file):\n",
    "    if file.endswith('.pt'):\n",
    "        data = load_pt(file)\n",
    "    elif file.endswith('.pkl'):\n",
    "        data = load_pkl(file)\n",
    "    elif file.endswith('.npy') or file.endswith('.npz'):\n",
    "        data = load_np(file)\n",
    "    return data\n",
    "\n",
    "def expand_dict(data,prefix='',depth=0, max_keys=1000):\n",
    "    indent = '    ' * depth\n",
    "    def _print(*args, **kwargs):print(indent[1:], *args, **kwargs)\n",
    "    if depth > 2:\n",
    "        _print(f'too deep, depth: {depth}')\n",
    "        return\n",
    "    _print(f'• LEN={len(data)}, DEPTH={depth}')\n",
    "    depth += 1\n",
    "\n",
    "    if isinstance(data, list):\n",
    "        for i,x in enumerate(data):\n",
    "            expand_dict(x, f'{prefix}列{i}一',depth)\n",
    "    elif isinstance(data,dict):\n",
    "        for k, v in data.items():\n",
    "            # 如果k有非下划线符号，全部替换成_\n",
    "            k = re.sub(r'[^a-zA-Z0-9_]', '_', k)\n",
    "\n",
    "            str_v = ''\n",
    "            if isinstance(v,np.ndarray):\n",
    "                str_v = f'{v.shape}\\t{v.dtype}'\n",
    "            elif not isinstance(v, dict):\n",
    "                str_v = str(v)\n",
    "            _print(f\"{k}:\\t{str(type(v))[8:-2]}\\t\\t{str_v}\")\n",
    "\n",
    "            if isinstance(v, dict):\n",
    "                expand_dict(v,f'{prefix}{k}一',depth)\n",
    "            else:\n",
    "                if isinstance(v, torch.Tensor) and v.size(0) == 1:\n",
    "                    _print(f'🧽 squeezed: {prefix}{k}')\n",
    "                    v = v.squeeze(0)\n",
    "                elif isinstance(v, np.ndarray):\n",
    "                    ...\n",
    "                if len(_GLOBAL.keys()) >= max_keys:\n",
    "                    _print(f'too many keys ,keys.len: {len(_GLOBAL.keys())}')\n",
    "                    return\n",
    "                _GLOBAL[f'{prefix}{k}'] = v\n",
    "\n",
    "def get_global(data, max_keys=50):\n",
    "    expand_dict(data, max_keys=max_keys)\n",
    "    globals().update(_GLOBAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " • LEN=2, DEPTH=0\n",
      "    • LEN=3, DEPTH=1\n",
      "    hand_bbox:\tlist\t\t[320.0, 392.0, 351.0, 433.0]\n",
      "    is_right:\tfloat\t\t1.0\n",
      "    wilor_preds:\tdict\t\t\n",
      "        • LEN=9, DEPTH=2\n",
      "        global_orient:\tnumpy.ndarray\t\t(1, 1, 3)\tfloat32\n",
      "        hand_pose:\tnumpy.ndarray\t\t(1, 15, 3)\tfloat32\n",
      "        betas:\tnumpy.ndarray\t\t(1, 10)\tfloat32\n",
      "        pred_cam:\tnumpy.ndarray\t\t(1, 3)\tfloat32\n",
      "        pred_keypoints_3d:\tnumpy.ndarray\t\t(1, 21, 3)\tfloat32\n",
      "        pred_vertices:\tnumpy.ndarray\t\t(1, 778, 3)\tfloat32\n",
      "        pred_cam_t_full:\tnumpy.ndarray\t\t(1, 3)\tfloat64\n",
      "        scaled_focal_length:\tnumpy.float64\t\t15859.375\n",
      "        pred_keypoints_2d:\tnumpy.ndarray\t\t(1, 21, 2)\tfloat64\n",
      "    • LEN=3, DEPTH=1\n",
      "    hand_bbox:\tlist\t\t[437.0, 360.0, 464.0, 402.0]\n",
      "    is_right:\tfloat\t\t0.0\n",
      "    wilor_preds:\tdict\t\t\n",
      "        • LEN=9, DEPTH=2\n",
      "        global_orient:\tnumpy.ndarray\t\t(1, 1, 3)\tfloat32\n",
      "        hand_pose:\tnumpy.ndarray\t\t(1, 15, 3)\tfloat32\n",
      "        betas:\tnumpy.ndarray\t\t(1, 10)\tfloat32\n",
      "        pred_cam:\tnumpy.ndarray\t\t(1, 3)\tfloat32\n",
      "        pred_keypoints_3d:\tnumpy.ndarray\t\t(1, 21, 3)\tfloat32\n",
      "        pred_vertices:\tnumpy.ndarray\t\t(1, 778, 3)\tfloat32\n",
      "        pred_cam_t_full:\tnumpy.ndarray\t\t(1, 3)\tfloat64\n",
      "        scaled_focal_length:\tnumpy.float64\t\t15859.375\n",
      "        pred_keypoints_2d:\tnumpy.ndarray\t\t(1, 21, 2)\tfloat64\n",
      "['列0一hand_bbox', '列0一is_right', '列0一wilor_preds一global_orient', '列0一wilor_preds一hand_pose', '列0一wilor_preds一betas', '列0一wilor_preds一pred_cam', '列0一wilor_preds一pred_keypoints_3d', '列0一wilor_preds一pred_vertices', '列0一wilor_preds一pred_cam_t_full', '列0一wilor_preds一scaled_focal_length', '列0一wilor_preds一pred_keypoints_2d', '列1一hand_bbox', '列1一is_right', '列1一wilor_preds一global_orient', '列1一wilor_preds一hand_pose', '列1一wilor_preds一betas', '列1一wilor_preds一pred_cam', '列1一wilor_preds一pred_keypoints_3d', '列1一wilor_preds一pred_vertices', '列1一wilor_preds一pred_cam_t_full', '列1一wilor_preds一scaled_focal_length', '列1一wilor_preds一pred_keypoints_2d']\n"
     ]
    }
   ],
   "source": [
    "_file = '/home/n/document/code/mocap/output/0_input_video/0_input_video.mp4_hand00.pt'\n",
    "get_global(load(_file))\n",
    "print(list(_GLOBAL.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mocap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
